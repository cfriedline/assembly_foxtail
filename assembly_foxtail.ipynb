{
 "metadata": {
  "name": "",
  "signature": "sha256:37cc290ce1d04d4b01f5b06efd9ce5fedefbc964376ed090ae2c4d890b1a3376"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Global imports"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from IPython.display import FileLink, FileLinks\n",
      "from IPython.parallel import Client\n",
      "import pickle\n",
      "import dill\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Set up local cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lc = Client()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview_local = lc[:]\n",
      "lview_local = lc.load_balanced_view()\n",
      "print len(lview_local)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Set up SGE cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rc = Client(profile='sge')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview = rc[:]\n",
      "lview = rc.load_balanced_view()\n",
      "print len(dview)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with dview.sync_imports(quiet=False):\n",
      "    import subprocess\n",
      "    import os\n",
      "    import sys\n",
      "    import socket\n",
      "    from collections import defaultdict\n",
      "    import stopwatch\n",
      "    import multiprocessing\n",
      "    import re\n",
      "    import numpy\n",
      "    import pandas\n",
      "    import scipy\n",
      "    import scipy.stats\n",
      "    import itertools\n",
      "    import shutil\n",
      "    import tempfile\n",
      "    from Bio.SeqIO.QualityIO import FastqGeneralIterator\n",
      "    import traceback"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dirname = \"/data7/cfriedline/assemblies/foxtail2\"\n",
      "os.chdir(dirname)\n",
      "res = dview.apply(os.chdir, dirname)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@dview.remote(block=True)\n",
      "def set_velvet_path():\n",
      "    os.environ['PATH'] = \"/data7/cfriedline/src/velvet\" + os.pathsep + os.environ['PATH']\n",
      "res = set_velvet_path()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files = !ls *.fastq"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@dview.remote(block=True)\n",
      "def get_hostname():\n",
      "    return socket.gethostname()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hostnames = sorted(get_hostname())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "unique_hosts = defaultdict(list)\n",
      "for i, h in enumerate(hostnames):\n",
      "    unique_hosts[h].append(i)\n",
      "    print i, h\n",
      "uview = [v[0] for k, v in unique_hosts.items()]\n",
      "luview = rc.load_balanced_view(targets=uview)\n",
      "duview = rc[uview]\n",
      "print len(uview)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_clean_stdout(s):\n",
      "    return [x.strip() for x in s.split(\"\\n\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Run VelvetOptimiser"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def set_omp_num_threads():\n",
      "    os.environ['OMP_NUM_THREADS'] = '16'\n",
      "dview['set_omp_num_threads'] = set_omp_num_threads\n",
      "res = dview.apply_sync(set_omp_num_threads)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_velvetoptimiser(args):\n",
      "    sys\n",
      "    print socket.gethostname(), args\n",
      "    timer = stopwatch.Timer()\n",
      "    f, k = args\n",
      "    dirname = os.path.dirname(f)\n",
      "    k_dir = os.path.join(dirname, \"%s_%d\" % (os.path.basename(f), k))\n",
      "    prefix = os.path.basename(k_dir)\n",
      "    out_dir = \"%s_data_%d\" % (prefix, k)\n",
      "    cmd = \"/home/cfriedline/src/VelvetOptimiser-2.2.5/VelvetOptimiser.pl --c tbp --s=%d --e=%d --x=0 --p %s --f '-fastq -short %s' --o '-unused_reads yes -read_trkg yes -amos_file yes'\" % (k, k, prefix, f)\n",
      "    os.chdir(dirname)\n",
      "    !$cmd\n",
      "    timer.stop()\n",
      "    return os.path.abspath(out_dir), timer.elapsed\n",
      "dview['run_velvetoptimiser'] = run_velvetoptimiser\n",
      "#run_velvetoptimiser((os.path.abspath(files[0]), 31))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# rerrun green 19\n",
      "green_tasks = []\n",
      "for f in files:\n",
      "    for k in k_list:\n",
      "        if \"Green\" in f and k == 19:\n",
      "            green_tasks.append((os.path.abspath(f), k))\n",
      "green_tasks = lview.map_async(run_velvetoptimiser, green_tasks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print green_tasks.metadata[0].stdout.split(\"\\n\")[-2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_list = xrange(19,65,2)\n",
      "tasks = []\n",
      "for f in files:\n",
      "    for k in k_list:\n",
      "        if 'Green_' in f:\n",
      "            if k == 23:\n",
      "                tasks.append((os.path.abspath(f), k))\n",
      "#         elif 'Yellow_' in f:\n",
      "#             if k == 21 or k == 23:\n",
      "#                 tasks.append((os.path.abspath(f), k))\n",
      "velvetoptimiser_results = lview.map_async(run_velvetoptimiser, tasks)\n",
      "            \n",
      "#     for k in k_list:\n",
      "#         tasks.append((os.path.abspath(f), k))\n",
      "# velvetoptimiser_results = lview.map_async(run_velvetoptimiser, tasks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tasks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for r in velvetoptimiser_results.metadata:\n",
      "    stdout = [x.strip() for x in r.stdout.split(\"\\n\")]\n",
      "    stderr = [x.strip() for x in r.stderr.split(\"\\n\")]\n",
      "    if len(stdout) > 1:\n",
      "#         print stdout[0]\n",
      "        if not r.completed:\n",
      "            print stdout[0].split()[0], stdout[-2], r.submitted\n",
      "        else:\n",
      "            print stdout[0], r.completed - r.started"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"%d/%d\" % (velvetoptimiser_results.progress, len(velvetoptimiser_results))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Run velveth"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_velveth(args):\n",
      "    timer = stopwatch.Timer()\n",
      "    f, k = args\n",
      "    dirname = os.path.dirname(f)\n",
      "    k_dir = os.path.join(dirname, \"%s_%d\" % (os.path.basename(f), k))\n",
      "    !/data7/cfriedline/src/velvet/velveth $k_dir $k -fastq -short $f\n",
      "    timer.stop()\n",
      "    return k_dir, timer.elapsed\n",
      "dview['run_velveth'] = run_velveth"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k_list = xrange(31,65,2)\n",
      "velveth_results = []\n",
      "for f in files:\n",
      "    for k in k_list:\n",
      "        velveth_results.append(lview.apply_async(run_velveth, (os.path.abspath(f), k)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "done = 0\n",
      "for r in velveth_results:\n",
      "    if not r.ready():\n",
      "        print \"*RUNNING*\", r.metadata.stdout.split(\"\\r\")[-2]\n",
      "    else:\n",
      "        done += 1\n",
      "        print \"*DONE\", r.r\n",
      "print done, \"/\", len(velveth_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Run velvetg\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_velvetg(args):\n",
      "    timer = stopwatch.Timer()\n",
      "    k_dir = args\n",
      "    !/data7/cfriedline/src/velvet/velvetg $k_dir -exp_cov auto\n",
      "    timer.stop()\n",
      "    return k_dir, timer.elapsed \n",
      "dview['run_velvetg'] = run_velvetg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "velvetg_results = []\n",
      "for r in velveth_results:\n",
      "    velvetg_results.append(luview.apply_async(run_velvetg, r.r[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "done = 0\n",
      "for r in velvetg_results:\n",
      "    if not r.ready():\n",
      "        stdout = r.metadata.stdout.split(\"\\n\")\n",
      "        print len(stdout)\n",
      "        if len(stdout) > 1:\n",
      "            print stdout[0]\n",
      "    else:\n",
      "        done +=1\n",
      "print done, \"/\", len(velvetg_results)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Build bowtie2 indexes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bowtie2_build(args):\n",
      "    timer = stopwatch.Timer()\n",
      "    velvet_dir = args\n",
      "    name = os.path.basename(velvet_dir)\n",
      "    contigs = os.path.join(velvet_dir, 'contigs.fa')\n",
      "    if os.path.exists(contigs):\n",
      "        !/data7/cfriedline/src/bowtie2-2.1.0/bowtie2-build -f $contigs $velvet_dir\n",
      "        timer.stop()\n",
      "        return velvet_dir, timer.elapsed\n",
      "    return None\n",
      "dview['bowtie2_build'] = bowtie2_build"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[x[0] for x in velvetomptimiser_results.r]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#build contigs.fa dirs manually:\n",
      "contig_files = !find . | grep contigs\n",
      "assembly_dirs = sorted([os.path.dirname(os.path.abspath(x)) for x in contig_files])\n",
      "assembly_dirs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bowtie_build_tasks = []\n",
      "# for r in velvetoptimiser_results.r:\n",
      "#     bowtie_build_tasks.append(r[0])\n",
      "for r in assembly_dirs:\n",
      "    if 'Green_26_ATCGCGCAA.fastq_23' in r:\n",
      "        #skip\n",
      "        print \"skipping\", r\n",
      "    else:\n",
      "        bowtie_build_tasks.append(r)\n",
      "# bowtie_build_tasks\n",
      "bowtie_build_results = lview.map_async(bowtie2_build, bowtie_build_tasks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "done = 0\n",
      "for m in bowtie_build_results.metadata:\n",
      "    stdout = [x.strip() for x in m.stdout.split(\"\\n\")]\n",
      "    if m.completed:\n",
      "        done += 1\n",
      "print \"%d/%d\" % (done, len(bowtie_build_results))\n",
      "bowtie_build_results.ready()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "max([r[1] for r in bowtie_build_results.r])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[r for r in bowtie_build_results.r]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Run bowtie2"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_bowtie2(args):\n",
      "    timer = stopwatch.Timer()\n",
      "    cpus = multiprocessing.cpu_count()\n",
      "    prefix, reads = args\n",
      "    sam = \"%s.sam\" % prefix\n",
      "    !/home/cfriedline/data7/src/bowtie2-2.1.0/bowtie2 --local --very-sensitive-local -p $cpus -x $prefix -U $reads -S $sam\n",
      "    timer.stop()\n",
      "    return prefix, sam, timer.elapsed\n",
      "dview['run_bowtie2'] = run_bowtie2   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contig_files = !find . | grep contigs.fa | grep _data_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contig_dirs_temp = sorted([(os.path.dirname(os.path.abspath(x)),0) for x in contig_files])\n",
      "contig_dirs = []\n",
      "for c in contig_dirs_temp:\n",
      "    if not 'Green_26_ATCGCGCAA.fastq_23' in c[0]:\n",
      "        contig_dirs.append(c)\n",
      "contig_dirs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bowtie_tasks = []\n",
      "#for r in bowtie_build_results.r:\n",
      "#run this if you don't have bowtie build results, using contig files from aboove\n",
      "for r in contig_dirs:  \n",
      "    prefix = r[0]\n",
      "    reads = \"_\".join(prefix.split(\"_\")[0:3])\n",
      "    bowtie_tasks.append((prefix, reads))\n",
      "bowtie_results = lview.map_async(run_bowtie2, bowtie_tasks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(bowtie_tasks)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print bowtie_results.ready(), bowtie_results.progress, len(bowtie_results)\n",
      "assembly_map_data = defaultdict(defaultdict)\n",
      "for i, r in enumerate(bowtie_results.metadata):\n",
      "    stdout = get_clean_stdout(r.stdout)\n",
      "    if len(stdout) > 1 and not \"Error\" in stdout[1]:\n",
      "        if bowtie_results.ready():\n",
      "            bowtie_results.r[i]\n",
      "            for s in stdout:\n",
      "#                 print r.stdout\n",
      "                m = re.search(r'(^\\d*\\.\\d*).*overall', s)\n",
      "                if m:\n",
      "                    percent_mapped = m.group(1)\n",
      "                    name_data = os.path.basename(bowtie_results.r[i][0]).split(\"_\")\n",
      "                    color = \"_\".join(name_data[0:2])\n",
      "                    k_size = float(name_data[-1])\n",
      "                    assembly_map_data[color][k_size] = float(percent_mapped)\n",
      "                    assembly_map_data[color]['stdout_%d' % k_size] = stdout"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bowtie_results_pickle = \"bowtie_results.pickle\"\n",
      "bowtie_results_metadata_pickle = \"bowtie_results_metadata.pickle\"\n",
      "pickle.dump(bowtie_results.r, open(bowtie_results_pickle, \"w\"))\n",
      "pickle.dump(bowtie_results.metadata, open(bowtie_results_metadata_pickle, \"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembly_map_data_pickle = \"assembly_map_data.pickle\"\n",
      "#pickle.dump(assembly_map_data, open(assembly_map_data_pickle, \"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%config InlineBackend.figure_format='retina'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "%history"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "assembly_map_data = pickle.load(open(\"/home/cfriedline/data7/assemblies/foxtail2/assembly_map_data.pickle\"))\n",
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "import matplotlib as mpl\n",
      "mpl.rc(\"font\", size=18)\n",
      "import matplotlib.pyplot as plt\n",
      "from IPython.display import Image\n",
      "plt.figure(figsize=(10,8))\n",
      "legend = []\n",
      "for name, v_dict in assembly_map_data.items():\n",
      "    marker = None\n",
      "    legend.append(name)\n",
      "    if \"Blue\" in name:\n",
      "        col = \"b\"\n",
      "        marker = \"s\"\n",
      "    elif \"Red\" in name:\n",
      "        col = 'r'\n",
      "        marker = \"D\"\n",
      "    elif \"Green\" in name:\n",
      "        col = 'g'\n",
      "        marker = '^'\n",
      "    elif 'Yellow' in name:\n",
      "        col = 'y'\n",
      "        marker = \"o\"\n",
      "    x = []\n",
      "    y = []\n",
      "    k_keys = sorted(v_dict.keys())\n",
      "    for k in k_keys:\n",
      "        if not 'stdout' in str(k) and k < 50:\n",
      "            x.append(k)\n",
      "            y.append(v_dict[k])\n",
      "        else:\n",
      "            pass\n",
      "            #print name, k, v_dict[k]\n",
      "#     plt.scatter(x, y, label=name, c=col, s=100, alpha=0.5)\n",
      "    plt.plot(x, y,color='black', marker=marker, label=name.split(\"_\")[0], markersize=10)\n",
      "plt.legend()\n",
      "plt.xlabel(\"k\")\n",
      "plt.ylabel(\"Percent mapped\")\n",
      "plt.xticks(xrange(11, 199, 2))\n",
      "plt.yticks(xrange(0, 100, 10))\n",
      "plt.ylim([0,85])\n",
      "plt.xlim([18,50])\n",
      "# plt.autoscale(enable=True, tight=False)\n",
      "plt.grid(True)\n",
      "fig = plt.gcf() #got to call before show() to be able to save\n",
      "plt.show()\n",
      "pp = PdfPages(\"mapping_performance.pdf\")\n",
      "pp.savefig(fig)\n",
      "pp.close()\n",
      "plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, r in enumerate(bowtie_results.r):\n",
      "    d = r[0]\n",
      "    from Bio import SeqIO\n",
      "    contigs = os.path.join(d, \"contigs.fa\")\n",
      "    count = 0\n",
      "    for rec in SeqIO.parse(open(contigs), \"fasta\"):\n",
      "        count +=1\n",
      "    print count, \"contigs in\", contigs\n",
      "    !tail -n1 $d/Log\n",
      "    print\"---\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Run LAP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process_mprob_cmd(reads, assembly, num_cpu, tmp_file):\n",
      "#     t = tempfile.NamedTemporaryFile(delete=False)\n",
      "#     for i, (n, s, q) in enumerate(FastqGeneralIterator(open(reads))):\n",
      "#         t.write(\"@%s\\n%s\\n+\\n%s\\n\" % (n, s, q))\n",
      "#         if i > 1000:\n",
      "#             break\n",
      "#     t.close()\n",
      "#     reads=t.name\n",
      "    stdout = \"\"\n",
      "    try: \n",
      "        #cmd = \"cat %s | /data7/cfriedline/src/lap_release_1.1/dynamic/mprobability -a %s -f fastq -p %d > %s\" % (reads, assembly, num_cpu, tmp_file)\n",
      "        #cmd = \"/data7/cfriedline/src/lap_release_1.1/dynamic/mprobability -a %s -f fastq -p %d < %s > %s\" % (assembly, num_cpu, reads, tmp_file)\n",
      "        cmd = \"cat %s | /home/cfriedline/data7/src/assembly-eval-code/src/dynamic/mprobability -a %s -f fastq -p %d > %s\" % (reads, assembly, num_cpu, tmp_file)\n",
      "        print cmd\n",
      "        lap_file = \"%s.lap\" % os.path.join(os.path.dirname(assembly))\n",
      "        stdout = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)\n",
      "        lap = !cat {tmp_file} | /data7/cfriedline/src/lap_release_1.1/dynamic/mean -t \"1e-150\"\n",
      "        shutil.copy(tmp_file, lap_file)\n",
      "        return [float(x) for x in lap[0].split(\"\\t\")], tmp_file, stdout\n",
      "    except subprocess.CalledProcessError as e:\n",
      "        print \"retcode:\\n\", e.returncode\n",
      "        print \"cmd:\\n\", e.cmd\n",
      "        print \"output:\\n\", e.output\n",
      "        print \"stdout/err:\\n\", stdout\n",
      "        return [], tmp_file, stdout\n",
      "dview['process_mprob_cmd'] = process_mprob_cmd \n",
      "    \n",
      "def run_lap_popen(args):\n",
      "    host = socket.gethostname()\n",
      "    print host\n",
      "    timer = stopwatch.Timer()\n",
      "    assembly, reads = args\n",
      "    lap_file = \"%s.lap\" % os.path.join(os.path.dirname(assembly))    \n",
      "    tasks = []\n",
      "    task_results = []    \n",
      "    if not os.path.exists(lap_file) or os.path.exists(lap_file):\n",
      "        num_cpu = multiprocessing.cpu_count()        \n",
      "        tmp_file = tempfile.NamedTemporaryFile(delete=False)\n",
      "        result = process_mprob_cmd(reads, assembly, num_cpu, tmp_file.name)\n",
      "        return host, lap_file, result, timer.elapsed\n",
      "dview['run_lap_popen'] = run_lap_popen\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_args = ('/data7/cfriedline/assemblies/foxtail2/Blue_61_CCTTATCAA.fastq_23_data_23/contigs.fa','/data7/cfriedline/assemblies/foxtail2/Blue_61_CCTTATCAA.fastq')\n",
      "run_lap_popen(test_args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lap_tasks = []\n",
      "# for a in velvetoptimiser_results.r:\n",
      "for a in contig_dirs:\n",
      "    assembly = os.path.join(a[0], 'contigs.fa')\n",
      "    reads = \"_\".join(assembly.split('_')[0:3])\n",
      "    lap_tasks.append(luview.apply_async(run_lap_popen, (assembly, reads)))\n",
      "#lap_tasks\n",
      "#lap_results = lview.map_async(run_lap_popen, lap_tasks)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ready = 0\n",
      "for t in lap_tasks:\n",
      "    if t.ready():\n",
      "        ready+=1\n",
      "print \"%d/%d\" % (ready, len(lap_tasks))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, t in enumerate(lap_tasks):\n",
      "    if t.ready():\n",
      "#         print \"-----------\\n\", i, \"\\t\", t.r, t.stdout,\"\\n===========\\n\"\n",
      "        print \"-----------\\n\", i, \"\\t\", t.r,\"\\n===========\\n\"\n",
      "    else:\n",
      "        print i, False\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lap_tasks_r_pickle = \"lap_tasks_r.pickle\"\n",
      "pickle.dump([t.r for t in lap_tasks], open(lap_tasks_r_pickle, \"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib as mpl\n",
      "mpl.rc(\"font\", size=18)\n",
      "from IPython.display import Image\n",
      "plt.figure(figsize=(10,8))\n",
      "legend = []\n",
      "plot_data = defaultdict(defaultdict)\n",
      "for t in lap_tasks:\n",
      "    col = None\n",
      "    marker = None\n",
      "    if t.ready():\n",
      "        name_data = os.path.basename(t[1]).split(\"_\")\n",
      "        color = name_data[0]\n",
      "        k = int(name_data[-3])\n",
      "        if \"Blue\" in color:\n",
      "            col = \"b\"\n",
      "            marker = \"s\"\n",
      "        elif \"Red\" in color:\n",
      "            col = 'r'\n",
      "            marker = \"D\"\n",
      "        elif \"Green\" in color:\n",
      "            col = 'g'\n",
      "            marker = '^'\n",
      "        elif 'Yellow' in color:\n",
      "            col = 'y'\n",
      "            marker = \"o\"\n",
      "        lap_data = t.r[2][0]\n",
      "        lap_mean = None\n",
      "        lap_sd = None\n",
      "        if len(lap_data) == 2:\n",
      "            lap_mean = lap_data[0]\n",
      "            lap_sd = lap_data[1]\n",
      "        plot_data[color][k] = {'mean':lap_mean, 'sd':lap_sd, 'marker':marker}\n",
      "color_keys = sorted(plot_data.keys())\n",
      "for color in color_keys:\n",
      "    k_data = plot_data[color]\n",
      "    x = []\n",
      "    y = []\n",
      "    err = []\n",
      "    x_err = []\n",
      "    y_err = []\n",
      "    keys = sorted(k_data.keys())\n",
      "    marker = None\n",
      "    for k in keys:\n",
      "        if k_data[k]['mean']:\n",
      "            x.append(k)\n",
      "            y.append(k_data[k]['mean'])\n",
      "            if marker is None:\n",
      "                marker = k_data[k]['marker']\n",
      "        if k_data[k]['sd']:\n",
      "            x_err.append(k)\n",
      "            y_err.append(k_data[k]['mean'])\n",
      "            err.append(k_data[k]['sd'])\n",
      "    plt.plot(x, y, color='black', marker=marker, label=color, markersize=10)\n",
      "#     plt.errorbar(x_err, y_err, yerr=err, ecolor=color,fmt=None)\n",
      "plt.legend()\n",
      "plt.xlabel(\"k\")\n",
      "plt.ylabel(\"LAP score\")\n",
      "plt.grid(True)\n",
      "plt.xticks(xrange(11, 63, 2))\n",
      "plt.yticks(xrange(-145, -100, 5))\n",
      "plt.xlim([18,50])\n",
      "plt.autoscale(False)\n",
      "fig = plt.gcf()\n",
      "plt.show()\n",
      "pp = PdfPages(\"lap_performance.pdf\")\n",
      "pp.savefig(fig)\n",
      "pp.close()\n",
      "plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /data7/cfriedline/assemblies/foxtail2/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lap_tasks = pickle.load(open(\"lap_tasks_r.pickle\"))\n",
      "from collections import defaultdict\n",
      "lap_scores = defaultdict()\n",
      "for t in lap_tasks:\n",
      "    name_data = os.path.basename(t[1]).split(\"_\")\n",
      "    color = name_data[0]\n",
      "    if not color in lap_scores:\n",
      "        lap_scores[color] = {'max_l':-1e50, 'max_f':None}\n",
      "    if len(t[2][0]):        \n",
      "        mean = t[2][0][0]\n",
      "        if mean > lap_scores[color]['max_l']:\n",
      "            lap_scores[color]['max_l'] = mean\n",
      "            lap_scores[color]['max_f'] = t[1]\n",
      "print lap_scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lap_scores_pickle = \"/data7/cfriedline/assemblies/foxtail2/lap_scores.pickle\"\n",
      "#pickle.dump(lap_scores, open(lap_scores_pickle, \"w\"))\n",
      "lap_scores = pickle.load(open(lap_scores_pickle))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lap_scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in lap_scores.items():\n",
      "    print k, v\n",
      "    for x, y in v.items():\n",
      "        print \"%s = %s\" % (x, str(y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in lap_scores.items():\n",
      "    max_f = os.path.abspath(v['max_f'])\n",
      "    contigs = os.path.join(max_f.replace(\".lap\", \"\"), 'contigs.fa')\n",
      "    assert os.path.exists(contigs)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Map individuals to best assembly"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print lap_scores.keys()\n",
      "print(lap_scores)\n",
      "#fastq_individuals = !find /home/cfriedline/eckertlab/bccl.csbc.vcu.edu/internal/Eckert -type f | grep .fastq$\n",
      "#just purple\n",
      "fastq_individuals_temp = !find /home/cfriedline/eckertlab/bccl.csbc.vcu.edu/internal/Eckert -type f | grep .fastq$\n",
      "fastq_individuals_temp2 = !find /home/cfriedline/data7/HiSeq_131001 -type f | grep .fastq$\n",
      "#fastq_individuals = sorted([x for x in fastq_individuals if \"Red_\" in x or \"Blue_\" in x or \"Green_\" in x or \"Purple_\" in x])\n",
      "# fastq_individuals = sorted([x for x in fastq_individuals if \"Blue_\" in x or \"Green_\" in x])\n",
      "fastq_individuals = []\n",
      "fastq_individuals_set = set()\n",
      "for x in fastq_individuals_temp:\n",
      "    if '_130529' in x:\n",
      "        base = os.path.basename(x)\n",
      "        if 'Green' in base or 'Red' in base:\n",
      "            if 'renamed' in x:\n",
      "                assert base not in fastq_individuals_set\n",
      "                fastq_individuals_set.add(base)\n",
      "                fastq_individuals.append(x)\n",
      "        elif 'Blue' in x:\n",
      "            assert base not in fastq_individuals_set\n",
      "            fastq_individuals_set.add(base)\n",
      "            fastq_individuals.append(x)            \n",
      "for x in fastq_individuals_temp2:\n",
      "    base = os.path.basename(x)\n",
      "    if 'Green' in base or 'Yellow' in base:\n",
      "        assert base not in fastq_individuals_set\n",
      "        fastq_individuals_set.add(base)\n",
      "        fastq_individuals.append(x)\n",
      "fastq_individuals = sorted(fastq_individuals)\n",
      "fastq_individuals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.path.abspath(lap_scores['Blue']['max_f'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fastq_individuals_with_assemblies = []\n",
      "for x in fastq_individuals:\n",
      "#     color = os.path.basename(x).split(\"_\")[0]\n",
      "    color = 'Green' #map everyone against the green assembly\n",
      "    if color in lap_scores.keys():\n",
      "        fastq_individuals_with_assemblies.append({'reads': x, 'sam':os.path.abspath(lap_scores[color]['max_f'].replace(\".lap\", \"\"))})\n",
      "fastq_individuals_with_assemblies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Run bowtie on individuals to call SNPs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_bowtie2_individuals(args):\n",
      "    timer = stopwatch.Timer()\n",
      "    cpus = multiprocessing.cpu_count()\n",
      "    prefix, reads = args\n",
      "    parent = os.path.dirname(prefix)\n",
      "    parent = \"/home/cfriedline/eckertlab/foxtail\"\n",
      "    individuals_dir = os.path.join(parent, \"individuals_all\")\n",
      "    if not os.path.exists(individuals_dir):\n",
      "        os.mkdir(individuals_dir)\n",
      "    sam = os.path.join(individuals_dir, \"%s.sam\" % os.path.basename(reads))\n",
      "    print \"/home/cfriedline/data7/src/bowtie2-2.1.0/bowtie2 --local --very-sensitive-local -p %d -x %s -U %s -S %s\" % (cpus, prefix, reads, sam)\n",
      "    !/home/cfriedline/data7/src/bowtie2-2.1.0/bowtie2 --local --very-sensitive-local -p $cpus -x $prefix -U $reads -S $sam\n",
      "    timer.stop()\n",
      "    return prefix, sam, timer.elapsed\n",
      "dview['run_bowtie2_individuals'] = run_bowtie2_individuals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bowtie_indviduals_tasks = []\n",
      "for x in fastq_individuals_with_assemblies:\n",
      "    bowtie_indviduals_tasks.append((x['sam'], x['reads']))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bowtie_indviduals_tasks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bowtie_indviduals_tasks_results = []\n",
      "for t in bowtie_indviduals_tasks:\n",
      "    bowtie_indviduals_tasks_results.append(lview.apply_async(run_bowtie2_individuals, t))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ready = 0\n",
      "for t in bowtie_indviduals_tasks_results:\n",
      "#     print t.ready()\n",
      "    if t.ready():\n",
      "        ready+=1\n",
      "#         print t.r\n",
      "print \"%d/%d\" % (ready, len(bowtie_indviduals_tasks_results))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle_file = \"/home/cfriedline/eckertlab/foxtail/individuals_all/bowtie_indviduals_tasks_results_all.r.pickle\"\n",
      "pickle.dump([t.r for t in bowtie_indviduals_tasks_results], open(pickle_file, \"w\"))\n",
      "#bowtie_indviduals_tasks_results = pickle.load(open(pickle_file))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Call SNPs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convert_sam_to_bam(sam):\n",
      "    timer = stopwatch.Timer()\n",
      "    cpus = multiprocessing.cpu_count()\n",
      "    bam = sam.replace(\".sam\", \".bam\")\n",
      "    bam_sorted = \"%s_sorted.bam\" % bam.replace(\".bam\", \"\")\n",
      "    bam_index = bam_sorted.replace(\".bam\", \".bai\")\n",
      "    !/home/cfriedline/data7/src/samtools-0.1.19/samtools view -bS $sam > $bam\n",
      "    !/home/cfriedline/data7/src/samtools-0.1.19/samtools sort -@ $cpus -f $bam $bam_sorted\n",
      "    !/home/cfriedline/data7/src/samtools-0.1.19/samtools index $bam_sorted $bam_index\n",
      "    timer.stop()\n",
      "    return bam, bam_sorted, bam_index, timer.elapsed\n",
      "dview['convert_sam_to_bam']  = convert_sam_to_bam"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bam_files = lview.map_async(convert_sam_to_bam, [x[1] for x in [t.r for t in bowtie_indviduals_tasks_results]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print bam_files.progress, len(bam_files), bam_files.ready(), bam_files.elapsed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x in bam_files.r:\n",
      "    print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pickle\n",
      "pickle_file = \"/home/cfriedline/eckertlab/foxtail/individuals_all/bam_files_all.r.pickle\"\n",
      "pickle.dump(bam_files.r, open(pickle_file, \"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#if you need to...\n",
      "import pickle\n",
      "pickle_file = \"/data7/cfriedline/assemblies/foxtail2/bam_files.r.pickle\"\n",
      "bam_files = pickle.load(open(pickle_file))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_ploidy_file(bam_files):\n",
      "    d = os.path.dirname(bam_files[0])\n",
      "    base = os.path.basename(bam_files[0])\n",
      "#     ploidy_file = os.path.join(d, \"%s.ploidy\" % base.split(\"_\")[0])\n",
      "    ploidy_file = os.path.join(d, \"%s.ploidy\" % \"all\")\n",
      "    if not os.path.exists(ploidy_file):\n",
      "        with open(ploidy_file, \"w\") as o:\n",
      "            for b in bam_files:\n",
      "                ploidy = 1\n",
      "                if \"-\" in os.path.basename(b):\n",
      "                    ploidy = 2\n",
      "                o.write(\"%s\\t%d\\n\" % (b, ploidy))\n",
      "    return ploidy_file\n",
      "dview['create_ploidy_file'] = create_ploidy_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def call_snps(args):\n",
      "    print socket.gethostname()\n",
      "    timer = stopwatch.Timer()\n",
      "    samtools, reference, bam_sorted, bcftools, raw_bcf, vcfutils, raw_vcf, out_dir = args \n",
      "    if not out_dir:\n",
      "        out_dir = os.environ['TMPDIR']\n",
      "    raw_bcf = os.path.join(out_dir, raw_bcf)\n",
      "    raw_vcf = os.path.join(out_dir, raw_vcf)\n",
      "    ploidy_file = create_ploidy_file(bam_sorted)\n",
      "    pileup = \"%s mpileup -uf %s %s | %s view -s %s -bvcg - > %s\" % (samtools, reference, ' '.join(bam_sorted), bcftools, ploidy_file, raw_bcf) \n",
      "    view_filter = \"%s view -s %s %s | %s varFilter -D100 > %s\" % (bcftools, ploidy_file, raw_bcf, vcfutils, raw_vcf)\n",
      "    print pileup\n",
      "    !$pileup\n",
      "    print view_filter\n",
      "    !$view_filter\n",
      "    timer.stop()\n",
      "    return raw_vcf, args, pileup, view_filter, timer.elapsed\n",
      "dview['call_snps'] = call_snps"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# in case you need to rebuild the indexes\n",
      "!find . -type f | grep fai | xargs rm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "samtools = \"/home/cfriedline/data7/src/samtools-0.1.19/samtools\"\n",
      "bcftools = \"/home/cfriedline/data7/src/samtools-0.1.19/bcftools/bcftools\"\n",
      "vcfutils = \"/home/cfriedline/data7/src/samtools-0.1.19/bcftools/vcfutils.pl\"\n",
      "snp_tasks = defaultdict(defaultdict)\n",
      "for x in bam_files:\n",
      "    bam, bam_sorted, bam_index, elapsed = x\n",
      "    out_dir = os.path.dirname(bam)\n",
      "    color = os.path.basename(bam).split(\"_\")[0]\n",
      "    color=\"Green\"\n",
      "    reference = os.path.join(os.path.abspath(lap_scores[color]['max_f'].replace(\".lap\", \"\")), \"contigs.fa\")\n",
      "    ref_index = \"%s.fai\" % reference\n",
      "    assert os.path.exists(reference)\n",
      "    if not os.path.exists(ref_index):\n",
      "        print \"indexing %s\" % reference\n",
      "        !/home/cfriedline/data7/src/samtools-0.1.19/samtools faidx $reference\n",
      "    snp_tasks[color]['reference'] = reference\n",
      "    if not 'bams' in snp_tasks[color]:\n",
      "        snp_tasks[color]['bams'] = []\n",
      "    snp_tasks[color]['bams'].append(bam_sorted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.environ['TMPDIR']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "out_dir = None\n",
      "for k, v in snp_tasks.items():\n",
      "    args = samtools, v['reference'], v['bams'], bcftools, \"%s.raw.bcf\" % k, vcfutils, \"%s.raw.vcf\" % k, out_dir\n",
      "    v['input_tmp'] = args"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in snp_tasks.items():\n",
      "    print k\n",
      "    print v['input_tmp']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in snp_tasks.items():\n",
      "    v['output_tmp'] = lview.apply_async(call_snps, v['input_tmp'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "done = 0\n",
      "for k, v in snp_tasks.items():\n",
      "    r = v['output_tmp']\n",
      "    print r.ready(), \n",
      "    if r.ready():\n",
      "        print \"**DONE\", r.r[0], r.r[-1], (r.completed-r.started)\n",
      "        done += 1        \n",
      "    else:\n",
      "        for x in r.stdout.strip().split(\"\\n\"):\n",
      "            print x\n",
      "            print \"elapsed: %.2f\" % r.elapsed\n",
      "    \n",
      "print \"done=%d\" % done"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "done = 0\n",
      "for k, v in snp_tasks.items():\n",
      "    r = v['output']\n",
      "    print r.ready(), \n",
      "    if r.ready():\n",
      "        print \"**DONE\", r.r[0], r.r[-1], (r.completed-r.started)\n",
      "        done += 1        \n",
      "    else:\n",
      "        for x in r.stdout.strip().split(\"\\n\"):\n",
      "            print x\n",
      "            print \"elapsed: %.2f\" % r.elapsed\n",
      "    \n",
      "print \"done=%d\" % done"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import FileLink, FileLinks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "home = os.environ['SGE_CWD_PATH']\n",
      "link = os.path.join(home, \"foxtail2_snps\")\n",
      "if not os.path.exists(link):\n",
      "    !ln -s {os.path.dirname(snp_results.r[0][0])} {link}\n",
      "FileLinks(link, included_suffixes=['.vcf'], notebook_display_formatter=None, url_prefix=\"files/\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vcf_files = !ls /home/cfriedline/eckertlab/foxtail/individuals_all/*.vcf | grep -v markers | grep -v filtered"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vcf_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vcftools = \"/home/cfriedline/data7/src/vcftools_0.1.11/bin/vcftools\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_vcftools(f):\n",
      "    print socket.gethostname()\n",
      "    !/home/cfriedline/data7/src/vcftools_0.1.11/bin/vcftools --vcf $f --remove-indels --minGQ 5 --012 --out $f\n",
      "    return f\n",
      "dview['run_vcftools'] = run_vcftools\n",
      "# dview_local['run_vcftools'] = run_vcftools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vcftools_all = lview.map_async(run_vcftools, vcf_files)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if vcftools_all.ready():\n",
      "#     print vcftools_all.r\n",
      "    print vcftools_all.r\n",
      "else:\n",
      "    print vcftools_all.progress"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ~/data7/assemblies/foxtail2/individuals/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /home/cfriedline/eckertlab/foxtail/individuals_all"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genotypes = !ls *.012 | grep -v filt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "genotypes = [os.path.abspath(x) for x in genotypes]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genotypes"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import defaultdict\n",
      "import pandas\n",
      "genotype_data = defaultdict(defaultdict)\n",
      "ploidy_file = \"all.ploidy\"\n",
      "ploidy_data = [os.path.basename(line.strip().split()[0])[0] for line in open(ploidy_file)]\n",
      "ploidy_set = sorted(list(set(ploidy_data)))\n",
      "for g in genotypes:\n",
      "    print g\n",
      "    g_list = defaultdict(list)\n",
      "    with open(g) as f:\n",
      "        for i, line in enumerate(f):\n",
      "            color = ploidy_data[i]\n",
      "            g_list[color].append(line.strip().split(\"\\t\"))            \n",
      "    for color in ploidy_set:\n",
      "        df = pandas.DataFrame(np.array(g_list[color]))\n",
      "        if not 'df' in genotype_data[os.path.basename(g)]:\n",
      "            genotype_data[os.path.basename(g)]['df'] = {}\n",
      "        genotype_data[os.path.basename(g)]['df'][color] = df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import multiprocessing\n",
      "pool = multiprocessing.Pool()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pool.close()\n",
      "pool.join()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in genotype_data.items():\n",
      "    df = v['df']\n",
      "    v['res'] = {}\n",
      "    for color, d in df.items():\n",
      "        print k, color, len(d), len(d.columns)\n",
      "        count_tasks = []\n",
      "        for i in xrange(len(d.columns)):\n",
      "            count_tasks.append(d[i])\n",
      "        v['res'][color] = pool.map_async(pandas.value_counts, count_tasks, chunksize=1000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in genotype_data.items():\n",
      "    for color, d in v['res'].items():\n",
      "        print color, d.ready()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_obs_f(series):\n",
      "    obs = []\n",
      "    for x in ['0', '1', '2', '-1']:\n",
      "        if x in series:\n",
      "            obs.append(float(series[x]))\n",
      "        else:\n",
      "            obs.append(0.0)\n",
      "    return numpy.array(obs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_corrected_p(p, alpha, num):\n",
      "    s = alpha/num\n",
      "    return numpy.array([s, p < s])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "timer = stopwatch.Timer()\n",
      "for k, v in genotype_data.items():\n",
      "    print k\n",
      "    v['sig'] = {}\n",
      "    v['alpha'] = {}\n",
      "    for color, data in v['res'].items():\n",
      "        t2 = stopwatch.Timer()\n",
      "        d = data.get()[1:]\n",
      "        v['sig'][color] = []\n",
      "        num_snps = len(d)\n",
      "        for i, x in enumerate(d):\n",
      "            alpha = 0.05\n",
      "            obs_f = get_obs_f(x)\n",
      "            obs = obs_f[0:3:2] #only picking 0/2 counts\n",
      "            x2 = -1\n",
      "            p = -1\n",
      "            p_cor = numpy.array([-1,1]) #exclude cases where no 0 or 2 genotypes\n",
      "            if sum(obs) >s 0:\n",
      "                x2, p = scipy.stats.chisquare(obs) \n",
      "                p_cor = get_corrected_p(p, alpha, num_snps)\n",
      "            v['sig'][color].append([i, obs_f.tolist(), x2, p, p_cor.tolist()])\n",
      "            v['alpha'][color] = alpha\n",
      "        t2.stop()\n",
      "        print \"%s (%s) done in %s\" % (k, color, t2)\n",
      "timer.stop()\n",
      "print \"done in %s\" % timer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in genotype_data.items():\n",
      "    print k\n",
      "    v['keep'] = {}\n",
      "    v['drop'] = {}\n",
      "    for color, data in v['sig'].items():\n",
      "        keep = []\n",
      "        drop = []\n",
      "        for x in data:\n",
      "            if x[-1][-1] == 0: #not significant\n",
      "                keep.append(x)\n",
      "            else:\n",
      "                drop.append(x)\n",
      "        v['keep'][color] = keep\n",
      "        v['drop'][color] = drop\n",
      "        print color, len(keep), len(drop)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import copy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in genotype_data.items():\n",
      "    v['df2'] = {}\n",
      "    for color, data in v['df'].items():\n",
      "        print k, color\n",
      "        v['df2'][color] = copy.copy(v['df'][color])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in genotype_data.items():\n",
      "    for color, data in v['drop'].items():\n",
      "        print k, color\n",
      "        drop = [x[0]+1 for x in data] #b/c there's the first col for the sample #'s\n",
      "        v['df2'][color] = v['df2'][color].drop(drop,1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in genotype_data.items():\n",
      "    for color, data in v['df'].items():\n",
      "        print k, color\n",
      "        print len(v['df'][color].columns), len(v['df2'][color].columns)\n",
      "        print v['df'][color].columns[0:10], v['df2'][color].columns[0:10]\n",
      "        h = open(\"%s_%s_filt_%.2f.012\" % (k,color,v['alpha'][color]), \"w\")\n",
      "        v['df2'][color].to_csv(h, sep=\"\\t\", header=True, index=False)\n",
      "        h.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in genotype_data.items():\n",
      "    for color, data in v['sig'].items():\n",
      "        print k, color\n",
      "        h = open(\"%s_%s_%.2f.stat\" % (k, color, v['alpha'][color]), \"w\")\n",
      "        h.write(\"#\\t0\\t1\\t2\\t-1\\tx2\\tp\\tp_cor\\tsig\\n\")\n",
      "        for x in data:\n",
      "            line = \"\"\n",
      "            for y in x:\n",
      "                if isinstance(y, list):\n",
      "                    line += \"\\t\".join([str(z) for z in y])\n",
      "                else:\n",
      "                    line += \"\\t\" + str(y) + \"\\t\"\n",
      "            h.write(\"%s\\n\" % '\\t'.join([a for a in line.split(\"\\t\") if a != '']))                      \n",
      "        h.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered_zip = \"snps_filtered_all_split_0.05.zip\"\n",
      "!rm $filtered_zip\n",
      "!zip $filtered_zip *012_*_filt_0.05.012\n",
      "!zip -g $filtered_zip *012_*_0.05.stat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Create corresponding pos file to go along with filtered 012 file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "z12 = \"Green.raw.vcf.012_filt_0.05.012\"\n",
      "posfile = \"Green.raw.vcf.012.pos\"\n",
      "h = open(z12)\n",
      "header = h.readline().split()\n",
      "h.close()\n",
      "header = [int(x) for x in header]\n",
      "keep_index = 0\n",
      "with open(\"%s_filt.pos\" % posfile, \"w\") as o:\n",
      "    for i, line in enumerate(open(posfile)):\n",
      "        if i == header[keep_index]:\n",
      "            o.write(line)\n",
      "            keep_index += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pool.close()\n",
      "pool.join()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ploidy_files = !ls *.ploidy\n",
      "zero12_files = !ls *.012"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for p in ploidy_files:\n",
      "    !wc -l $p\n",
      "for z in zero12_files:\n",
      "    !wc -l $z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Combine SNPs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Blast all maxL lap assemblies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "maxL_assemblies = sorted([os.path.join(v['max_f'][:-4], \"contigs.fa\") for k, v in lap_scores.items()])\n",
      "for a in maxL_assemblies:\n",
      "    assert os.path.exists(a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blast_tasks = []\n",
      "for a in maxL_assemblies:\n",
      "    for b in maxL_assemblies:\n",
      "        if not a in b:\n",
      "            blast_tasks.append((a, b))\n",
      "blast_tasks"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio.Blast.Applications import NcbiblastnCommandline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_blast_db(f):\n",
      "    !/home/cfriedline/src/ncbi-blast-2.2.28+/bin/makeblastdb -in {f} -dbtype nucl\n",
      "    \n",
      "for t in blast_tasks:\n",
      "    [make_blast_db(x) for x in t if not os.path.exists(x + \".nin\")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_blast(cmd):\n",
      "    print cmd\n",
      "    !{cmd}\n",
      "dview['run_blast'] = run_blast"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_short_filename(f):\n",
      "    return os.path.basename(os.path.dirname(f))\n",
      "blast_results = [] \n",
      "max_target_seqs=1\n",
      "for t in blast_tasks:\n",
      "    out_dir = os.path.dirname(os.path.dirname(t[0]))\n",
      "    out_dir = os.path.join(out_dir, \"blast_results\")\n",
      "    if not os.path.exists(out_dir):\n",
      "        os.mkdir(out_dir)\n",
      "    out_file = os.path.join(out_dir, \"%s-%s-max%d.xml\" % (get_short_filename(t[0]), get_short_filename(t[1]), max_target_seqs))\n",
      "    blastn = NcbiblastnCommandline(cmd=\"/home/cfriedline/src/ncbi-blast-2.2.28+/bin/blastn\", \n",
      "                                   query=t[0], \n",
      "                                   db=t[1], \n",
      "                                   out=out_file,\n",
      "                                   evalue=1e-5,\n",
      "                                   outfmt=5,\n",
      "                                   num_threads=multiprocessing.cpu_count(),\n",
      "                                   max_target_seqs=max_target_seqs)\n",
      "    blast_results.append(lview.apply_async(run_blast, str(blastn)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "working = 0\n",
      "done = 0\n",
      "for r in blast_results:\n",
      "    print r.ready()\n",
      "    if r.ready():\n",
      "        done += 1\n",
      "        print r.stdout,r.completed-r.started\n",
      "        print\n",
      "    else:\n",
      "        working += 1\n",
      "        print r.stdout\n",
      "print done, working"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio.Blast import NCBIXML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blast_result_xml = !ls  /home/cfriedline/data7/assemblies/foxtail2/blast_results | grep xml | grep -v max"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blast_result_xml = sorted([os.path.join(\"/home/cfriedline/data7/assemblies/foxtail2/blast_results\", x) for x in blast_result_xml])\n",
      "blast_result_xml"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with dview_local.sync_imports():\n",
      "    import networkx\n",
      "    import socket\n",
      "    from Bio.Blast import NCBIXML\n",
      "    import os\n",
      "    import pickle\n",
      "    import stopwatch\n",
      "    from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with dview.sync_imports():\n",
      "    import networkx\n",
      "    from Bio.Blast import NCBIXML\n",
      "    import os\n",
      "    import pickle\n",
      "    from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Create BLAST Graph"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_blast_graph(blast_result_xml):\n",
      "    query_percent_cutoff = 0.8\n",
      "    percent_id_cutoff = 0.8\n",
      "    short_queries = 0\n",
      "    query_percs = []\n",
      "    query_lengths = []\n",
      "    perc_ids = []\n",
      "    edges = []\n",
      "    G = networkx.DiGraph()\n",
      "    for blast_result_file in blast_result_xml:\n",
      "        blasted_files = os.path.basename(blast_result_file).split(\"-\")\n",
      "        q_color = blasted_files[0].split(\"_\")[0]\n",
      "        s_color = blasted_files[1].split(\"_\")[0]\n",
      "        print q_color, \"vs\", s_color\n",
      "        blast_recs = NCBIXML.parse(open(blast_result_file))\n",
      "        for i, rec in enumerate(blast_recs):\n",
      "            q = \"%s-%s\" % (q_color[0],  \"_\".join(rec.query.split(\"_\")[0:2]))\n",
      "            if len(rec.alignments) > 0:\n",
      "                query_lengths.append(rec.query_length)\n",
      "                for aln in rec.alignments:\n",
      "                    s = \"%s-%s\" % (s_color[0], \"_\".join(aln.hit_def.split(\"_\")[0:2]))\n",
      "                    for hsp in aln.hsps:\n",
      "                        q_len = abs(hsp.query_end - hsp.query_start) + 1.0\n",
      "                        q_perc = q_len/rec.query_length\n",
      "                        perc_id = float(hsp.identities)/hsp.align_length\n",
      "                        query_percs.append(q_perc)\n",
      "                        perc_ids.append(perc_id)\n",
      "                        if q_perc >= query_percent_cutoff and perc_id >= percent_id_cutoff:\n",
      "                            edges.append((q, s))\n",
      "                        else:\n",
      "                            short_queries += 1\n",
      "    G.add_edges_from(edges)\n",
      "    print \"short queries=%d\" % short_queries\n",
      "    return G, query_percs, query_lengths, query_percent_cutoff\n",
      "dview_local['create_blast_graph'] = create_blast_graph"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blast_graph = lview_local.apply_async(create_blast_graph, blast_result_xml)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print blast_graph.ready(), blast_graph.elapsed#, blast_graph.completed-blast_graph.started\n",
      "print blast_graph.stdout"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(blast_graph.r, open(\"/home/cfriedline/data7/assemblies/foxtail2/blast_g_max10_q80i80.pickle\", 'w'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bg_m10q80i80, query_percs_m10q80i80, query_lengths_m10q80i80, cutoff_m10q80i80 = blast_graph.r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bg_m10q80i80, query_percs_m10q80i80, query_lengths_m10q80i80, cutoff_m10q80i80 = pickle.load(open(\"/home/cfriedline/data7/assemblies/foxtail2/blast_g_max10_q80i80.pickle\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Build Blast xml indexes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import SearchIO\n",
      "blast_index_dict = defaultdict(defaultdict)\n",
      "for f in blast_result_xml:\n",
      "    print f\n",
      "    idx = SearchIO.index(f, 'blast-xml')\n",
      "    blast_index_dict[f]['full'] = idx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blast_index_keys = sorted(list(blast_index_dict.keys()))\n",
      "for k in blast_index_keys:\n",
      "    basename = os.path.basename(k)\n",
      "    data = blast_index_dict[k]\n",
      "    data['short'] = defaultdict()\n",
      "    for key in data['full']:\n",
      "        prefix = basename[0] + \"-\"\n",
      "        short_name = prefix + '_'.join(key.split(\"_\")[0:2])\n",
      "        data['short'][short_name] = key    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, axs = plt.subplots(3,2)\n",
      "f.set_size_inches(12,12)\n",
      "axs[0][0].hist(query_percs, bins=100)\n",
      "axs[0][1].hist(query_lengths, bins=100)\n",
      "axs[1][0].hist(query_percs50, bins=100)\n",
      "axs[1][1].hist(query_lengths50, bins=100)\n",
      "axs[2][0].hist(query_percs1, bins=100)\n",
      "axs[2][1].hist(query_lengths1, bins=100)\n",
      "plt.show()\n",
      "print \"10:\", np.mean(query_lengths), np.std(query_lengths), np.max(query_lengths), np.min(query_lengths), len(bg)\n",
      "print \"50:\", np.mean(query_lengths50), np.std(query_lengths50), np.max(query_lengths50), np.min(query_lengths50), len(bg50)\n",
      "print \"1:\", np.mean(query_lengths1), np.std(query_lengths1), np.max(query_lengths1), np.min(query_lengths1), len(bg1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Test some filtering by degree (enforce star topology)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "i = 0\n",
      "filtered_graph = bg.copy()\n",
      "for b in filtered_graph.nodes():\n",
      "    i += 1\n",
      "    filtered_graph.predecessors\n",
      "    pred = set(filtered_graph.predecessors(b))\n",
      "    succ = set(filtered_graph.successors(b))\n",
      "    pred.add(b)\n",
      "    succ.add(b)\n",
      "    if len(set([x[0] for x in pred])) == 4 and len(set([x[0] for x in succ])) == 4:\n",
      "        continue\n",
      "    else: \n",
      "        filtered_graph.remove_node(b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " print len(bg), len(filtered_graph), len(bg.edges()), len(filtered_graph.edges())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "in_deg = bg.in_degree()\n",
      "out_deg = bg.out_degree()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f, axs = plt.subplots(1,2)\n",
      "f.set_size_inches(12,5)\n",
      "axs[0].hist(in_deg.values())\n",
      "axs[1].hist(out_deg.values())\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Get strongly connected components"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_scc(G):\n",
      "    return list(networkx.strongly_connected_component_subgraphs(G))\n",
      "# dview['get_scc'] = get_scc\n",
      "dview_local['get_scc'] = get_scc"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scc_m10q80i80 = lview_local.apply_async(get_scc, bg_m10q80i80)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print scc_m10q80i80.ready()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print scc_m10q80i80.ready(), scc_m10q80i80.completed-scc_m10q80i80.started"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scc_bg_m10q80i80 = scc_m10q80i80.r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(bg_m10q80)\n",
      "print len(bg_m10q80i80)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, s in enumerate(scc_bg_m10q80i80):\n",
      "    print len(s)\n",
      "    if i ==20:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, s in enumerate(scc_bg_m10q80):\n",
      "    print len(s)\n",
      "    if i ==20:\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(scc_bg_m10q80i80, open(\"/data7/cfriedline/assemblies/foxtail2/scc_bg_m10q80i80.pickle\", \"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scc_bg_m10q80i80 = pickle.load(open(\"/data7/cfriedline/assemblies/foxtail2/scc_bg_m10q80i80.pickle\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Add libraries property for ease of searching"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i, subgraph in enumerate(scc_bg_m10q80i80):\n",
      "    libs = set([x[0] for x in subgraph])\n",
      "    subgraph.graph['libs'] = libs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Build node-subgraph dict"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "node_subgraph_dict = {}\n",
      "for i, subgraph in enumerate(scc_bg_m10q80i80):\n",
      "    libs = subgraph.graph['libs']\n",
      "    for node in subgraph:\n",
      "        node_subgraph_dict[node] = {}\n",
      "        node_subgraph_dict[node]['index'] = i\n",
      "        node_subgraph_dict[node]['libs'] = libs \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Setup method to print graph to pdf"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def drop_graph_to_pdf(args):\n",
      "    import matplotlib\n",
      "    matplotlib.use('Agg')\n",
      "    import matplotlib.pyplot as plt\n",
      "    G, file_name, size = args\n",
      "    w, h = size\n",
      "    f = plt.gcf()\n",
      "    a = plt.gca()\n",
      "    f.set_size_inches(w,h)\n",
      "    a.set_xticks([]); a.set_yticks([])\n",
      "    plt.axis('off')\n",
      "    pos = networkx.random_layout(G)\n",
      "    colors = [x[0] for x in G]\n",
      "    networkx.draw_networkx_nodes(G, pos, node_color=colors, node_size=500)\n",
      "    networkx.draw_networkx_edges(G, pos, edge_color=\"#bababa\", style='dotted')\n",
      "    plt.savefig(file_name, bbox_inches='tight')\n",
      "    plt.close()\n",
      "    return file_name\n",
      "dview_local['drop_graph_to_pdf'] = drop_graph_to_pdf\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bg0_pdf = lview_local.apply_async(drop_graph_to_pdf, (scc_bg_m1q80[0], \"/home/cfriedline/data7/assemblies/foxtail2/scc_bg_m1q80_0.pdf\", (100,100)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bg0_pdf.ready()\n",
      "if bg0_pdf.ready():\n",
      "    print bg0_pdf.completed-bg0_pdf.started\n",
      "    print bg0_pdf.r"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Setup test for strongly connected components"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(test_scc, open(\"test_scc.pickle\", \"w\"))\n",
      "pickle.dump(G_test, open(\"g_test.pickle\", \"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx\n",
      "# G_test = nx.DiGraph()\n",
      "# test_nodes = 30\n",
      "# remove_perc = 0.95\n",
      "# G_test.add_nodes_from(list(xrange(test_nodes)))\n",
      "# for i in xrange(test_nodes):\n",
      "#     for j in xrange(i):\n",
      "#         G_test.add_edge(i, j)\n",
      "#         G_test.add_edge(j, i)\n",
      "# to_remove_indices = np.random.choice(len(G_test.edges()), int(len(G_test.edges())*remove_perc), replace=False)\n",
      "# to_remove = []\n",
      "# for r in to_remove_indices:\n",
      "#     to_remove.append(G_test.edges()[r])\n",
      "# G_test.remove_edges_from(to_remove)\n",
      "G_test = pickle.load(open(\"g_test.pickle\"))\n",
      "global_pos = nx.shell_layout(G_test)\n",
      "f = plt.gcf()\n",
      "f.set_size_inches(20, 20)\n",
      "a = plt.gca()\n",
      "a.set_xticks([]); a.set_yticks([])\n",
      "plt.axis('off')\n",
      "nx.draw_networkx_nodes(G_test, global_pos, node_color='black', node_size=2000)\n",
      "nx.draw_networkx_edges(G_test, global_pos)\n",
      "plt.savefig(\"g1.pdf\", bbox_inches='tight')\n",
      "plt.show()\n",
      "plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test_scc = list(nx.strongly_connected_component_subgraphs(G_test))\n",
      "test_scc = pickle.load(open(\"test_scc.pickle\"))\n",
      "import matplotlib.cm as cm\n",
      "print len(test_scc)\n",
      "f = plt.gcf()\n",
      "f.set_size_inches(20, 20)\n",
      "a = plt.gca()\n",
      "a.set_xticks([]); a.set_yticks([])\n",
      "plt.axis('off')\n",
      "style = ['solid', 'dashed', 'dotted', 'dashdot']\n",
      "style_id = 0\n",
      "for i, x in enumerate(test_scc):\n",
      "    color=cm.binary(float(i)/(len(test_scc)))\n",
      "    nx.draw_networkx_nodes(x, global_pos, node_color=color, node_size=2000)\n",
      "    nx.draw_networkx_edges(x, global_pos, style=style[style_id])\n",
      "    style_id += 1\n",
      "    if style_id == len(style):\n",
      "        style_id = 0    \n",
      "plt.savefig(\"g2.pdf\", bbox_inches='tight')\n",
      "plt.show()\n",
      "plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "individuals_dir = \"/home/cfriedline/data7/assemblies/foxtail2/individuals\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genotypes = !ls $individuals_dir | grep filt.012$"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pos_files = !ls $individuals_dir | grep vcf.012.pos\n",
      "pos_files = sorted([os.path.join(individuals_dir, x) for x in pos_files])\n",
      "pos_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stat_files = !ls $individuals_dir | grep vcf.012.stat | grep -v shared\n",
      "stat_files = sorted([os.path.join(individuals_dir, x) for x in stat_files])\n",
      "stat_files"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Add sharing to new file based on graph connectivity"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_shared = 0\n",
      "total_not_shared = 0\n",
      "missing_hits = set()\n",
      "shared_counts = defaultdict(int)\n",
      "for pos_file, stat_file in zip(pos_files, stat_files):\n",
      "    pf = open(pos_file)\n",
      "    sf = open(stat_file)\n",
      "    s_head = sf.readline().strip()\n",
      "    count = 0\n",
      "    prefix = os.path.basename(pos_file)[0]+\"-\"\n",
      "    out = stat_file + \".shared\"\n",
      "    print out\n",
      "    with open(out, \"w\") as o:\n",
      "        o.write(\"id\\tG0\\tG1\\tG2\\tG-1\\tx2\\tp\\tp_cor\\tsig\\tlib_num\\tlibs\\n\")\n",
      "        for p_line, s_line in zip(pf, sf):\n",
      "            p_line = p_line.strip()\n",
      "            s_line = s_line.strip()\n",
      "            name = prefix + '_'.join(p_line.split(\"_\")[0:2])\n",
      "            libs = name[0]\n",
      "            if name in node_subgraph_dict:\n",
      "                libs = node_subgraph_dict[name]['libs']\n",
      "                if len(libs) == 4:\n",
      "                    total_shared += 1\n",
      "                    shared_counts[name[0]] += 1\n",
      "                else:\n",
      "                    total_not_shared += 1\n",
      "            else:\n",
      "                missing_hits.add(name)\n",
      "            s_new = \"\\t\".join([name, s_line, str(len(libs)), \"\".join(sorted(list(libs)))])\n",
      "            o.write(\"%s\\n\" % s_new)\n",
      "            count += 1\n",
      "print \"total shared = %d, not shared = %d\" % (total_shared, total_not_shared)\n",
      "print \"missing hits for\", len(missing_hits)\n",
      "print \"shared counts\", [(k, v) for k, v in shared_counts.items()]\n",
      "# for x in sorted(list(missing_libs)):\n",
      "#     print x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Results filtering by query percent (80) and identity (80)"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "/home/cfriedline/data7/assemblies/foxtail2/individuals/Blue.raw.vcf.012.stat.shared\n",
      "/home/cfriedline/data7/assemblies/foxtail2/individuals/Green.raw.vcf.012.stat.shared\n",
      "/home/cfriedline/data7/assemblies/foxtail2/individuals/Red.raw.vcf.012.stat.shared\n",
      "/home/cfriedline/data7/assemblies/foxtail2/individuals/Yellow.raw.vcf.012.stat.shared\n",
      "total shared = 10185, not shared = 323160\n",
      "missing hits for 169674\n",
      "shared counts [('Y', 1291), ('R', 4636), ('B', 2690), ('G', 1568)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Previous results without filtering by percent identity"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "/home/cfriedline/data7/assemblies/foxtail2/individuals/Blue.raw.vcf.012.stat.shared\n",
      "/home/cfriedline/data7/assemblies/foxtail2/individuals/Green.raw.vcf.012.stat.shared\n",
      "/home/cfriedline/data7/assemblies/foxtail2/individuals/Red.raw.vcf.012.stat.shared\n",
      "/home/cfriedline/data7/assemblies/foxtail2/individuals/Yellow.raw.vcf.012.stat.shared\n",
      "total shared = 10781, not shared = 323313\n",
      "missing hits for 169564\n",
      "shared counts [('Y', 1338), ('R', 4839), ('B', 2912), ('G', 1692)]"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Get shortest path between contigs for those that are shared"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scc = scc_bg_m10q80i80\n",
      "shared_nodes = [x for x in node_subgraph_dict if len(node_subgraph_dict[x]['libs'])==4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(shared_nodes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def compute_all_shortest_paths(args):\n",
      "#     shared_nodes, node_subgraph_dict = args\n",
      "#     path_dict = defaultdict()\n",
      "#     for i, node in enumerate(shared_nodes):\n",
      "#         path_dict[node] = {}\n",
      "#         libs = node_subgraph_dict[node]['libs']\n",
      "#         idx = node_subgraph_dict[node]['index']\n",
      "#         G = scc[idx]\n",
      "#         print i, node, len(G)\n",
      "#         for target in G:\n",
      "#             asp = nx.all_shortest_paths(G, node, target)\n",
      "#             color = target[0]\n",
      "#             for path in asp:\n",
      "#                 path_len = len(path)-1\n",
      "#                 if not color in path_dict[node]:\n",
      "#                     path_dict[node][color] = [[target], path_len]\n",
      "#                 else:\n",
      "#                     if path_len < path_dict[node][color][1]:\n",
      "#                         path_dict[node][color] = [[target], path_len]\n",
      "#                     elif path_len == path_dict[node][color][1]:\n",
      "#                         path_dict[node][color][0].append(target)\n",
      "#     return path_dict\n",
      "# dview_local['compute_all_shortest_paths'] = compute_all_shortest_paths"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# asp_job = lview.apply_async(compute_all_shortest_paths, (shared_nodes, node_subgraph_dict))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# asp_job"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Compute single shortest path length for shared nodes in respective subgraphs (note that this is not all paths, in case of ties)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import networkx as nx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_dict = defaultdict()\n",
      "for node in shared_nodes:\n",
      "    path_dict[node] = {}\n",
      "    libs = node_subgraph_dict[node]['libs']\n",
      "    idx = node_subgraph_dict[node]['index']\n",
      "    G = scc[idx]\n",
      "    ssspl = nx.single_source_shortest_path_length(G, node)\n",
      "    for target, path_len in ssspl.items():\n",
      "        color = target[0]\n",
      "        if not color in path_dict[node] and nx.has_path(G, node, target):\n",
      "            path_dict[node][color] = [{target}, path_len]\n",
      "        else:\n",
      "            if path_len < path_dict[node][color][1] and nx.has_path(G, node, target):\n",
      "                path_dict[node][color] = [{target}, path_len]    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Compute all paths in the subgraph to account for ties in shortest path"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "shortest_path_pairs = {}\n",
      "for i, node in enumerate(shared_nodes):\n",
      "    if i % 100 == 0:\n",
      "        print i, node\n",
      "    libs = node_subgraph_dict[node]['libs']\n",
      "    idx = node_subgraph_dict[node]['index']\n",
      "    G = scc[idx]\n",
      "    max_len = max([x[1] for x in path_dict[node].values()])\n",
      "    pairs = None\n",
      "    if not G in shortest_path_pairs:\n",
      "        pairs = nx.all_pairs_shortest_path_length(G, cutoff=max_len)\n",
      "        shortest_path_pairs[G] = {max_len:pairs}\n",
      "    else:\n",
      "        max_len_key = max(shortest_path_pairs[G].keys())\n",
      "        if max_len > max_len_key:\n",
      "            pairs = nx.all_pairs_shortest_path_length(G, cutoff=max_len)\n",
      "            shortest_path_pairs[G][max_len] = pairs\n",
      "        else:\n",
      "            pairs = shortest_path_pairs[G][max_len_key]\n",
      "    for p in pairs[node]:\n",
      "        color = p[0]\n",
      "        if pairs[node][p] == path_dict[node][color][1] and nx.has_path(G, node, p):\n",
      "            path_dict[node][color][0].add(p)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in path_dict.items():\n",
      "    print k, v\n",
      "    break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def drop_graph_to_pdf_local(args):\n",
      "    import matplotlib.pyplot as plt\n",
      "    G, file_name, size = args\n",
      "    w, h = size\n",
      "    f = plt.gcf()\n",
      "    a = plt.gca()\n",
      "    f.set_size_inches(w,h)\n",
      "    a.set_xticks([]); a.set_yticks([])\n",
      "    a.title.set_fontsize(100)\n",
      "    plt.axis('off')\n",
      "    pos = networkx.random_layout(G)\n",
      "    colors = [x[0] for x in G]\n",
      "    shape_map = {\"B\":\"s\", \"G\":\"^\", \"R\":\"d\", \"Y\":\"o\"}\n",
      "    label_map = {\"B\":\"Blue\", \"G\":\"Green\", \"R\":\"Red\", \"Y\":\"Yellow\"}\n",
      "    labels = ['B', 'R', 'Y', 'G']\n",
      "    nodelist_map = defaultdict(list)\n",
      "    for node in G:\n",
      "        nodelist_map[node[0]].append(node)\n",
      "    for k in labels:\n",
      "        label = label_map[k]\n",
      "        nodelist = nodelist_map[k]\n",
      "        networkx.draw_networkx_nodes(G, pos, nodelist=nodelist, node_color='black', node_size=500, node_shape=shape_map[k], label=label)\n",
      "    networkx.draw_networkx_edges(G, pos, style='dotted', width=0.2)\n",
      "    #plt.title(\"Strongly connected component subgraph of n=%d nodes\" % len(G))\n",
      "    plt.legend(markerscale=1, scatterpoints=1, loc=0, fontsize=20, bbox_to_anchor=(1.07,0.93))\n",
      "    plt.savefig(file_name, bbox_inches='tight')\n",
      "    plt.show()\n",
      "    plt.close()\n",
      "    return file_name\n",
      "dview_local['drop_graph_to_pdf_local'] = drop_graph_to_pdf_local"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keys = [\"R\", \"G\", \"B\", \"Y\"]\n",
      "with open(\"/home/cfriedline/data7/assemblies/foxtail2/individuals/path_info_m10q80i80.txt\", \"w\") as o:\n",
      "    o.write(\"%s\\n\" % \"\\t\".join(['source', 'R_contig', 'R_len', 'G_contig', 'G_len', 'B_contig', 'B_len', 'Y_contig', 'Y_len']))\n",
      "    sorted_keys = sorted(path_dict.keys())\n",
      "    for node in sorted_keys:\n",
      "        data = path_dict[node]\n",
      "        line = [node]\n",
      "        for k in keys:\n",
      "            d = data[k]\n",
      "            line.append(\"|\".join(d[0]))\n",
      "            line.append(d[1])\n",
      "        o.write(\"%s\\n\" % \"\\t\".join([str(x) for x in line]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Build contig indexes for best assemblies"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from Bio import SeqIO"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contig_dict = {}\n",
      "for x in lap_scores:\n",
      "    contig_file = os.path.join(lap_scores[x]['max_f'].replace(\".lap\", \"\"), \"contigs.fa\")\n",
      "    print contig_file\n",
      "    contig_dict[x[0]] = SeqIO.index(contig_file, \"fasta\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blast_name_map = {}\n",
      "for k, v in blast_index_dict.items():\n",
      "    for short_name in v['short']:\n",
      "        blast_name_map[short_name] = v['short'][short_name]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with dview_local.sync_imports():\n",
      "    from Bio.Emboss.Applications import NeedleCommandline\n",
      "    import cStringIO\n",
      "    import subprocess, sys\n",
      "    from Bio import AlignIO\n",
      "    import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def run_needle(args):\n",
      "    query_name, query_seq, target_name, target_seq, path_len, regex, strand = args\n",
      "    needle = NeedleCommandline(cmd='/home/cfriedline/emboss/bin/needle', \n",
      "                                       outfile='stdout', \n",
      "                                       asequence=\"%s:%s\" % (\"asis\", query_seq),\n",
      "                                       bsequence=\"%s:%s\" % (\"asis\", target_seq),\n",
      "                                       gapopen=10,\n",
      "                                       gapextend=0.5,\n",
      "                                       brief=True)\n",
      "    stdout, stderr = needle()\n",
      "    s = stdout\n",
      "    m = regex.search(s)\n",
      "    if m:\n",
      "        percent_id = m.group(3)\n",
      "        return query_name, target_name, path_len, percent_id, strand, s\n",
      "    return None\n",
      "\n",
      "#Identity:      55/68 (80.9%)\n",
      "needle_id_regex = re.compile(\"Identity:\\s+(\\d+)/(\\d+)\\s\\((\\d+\\.\\d+)%\\)\")\n",
      "count = 0\n",
      "needle_jobs = []\n",
      "for node, data in path_dict.items():\n",
      "    #print node, data\n",
      "    full_name = blast_name_map[node]\n",
      "    query_seq = contig_dict[node[0]][full_name]\n",
      "    \n",
      "    for key, target in data.items():\n",
      "        for t in target[0]:\n",
      "            target_full_name = blast_name_map[t]\n",
      "            target_seq = contig_dict[t[0]][target_full_name]\n",
      "            needle_jobs.append((node, query_seq.seq, t, target_seq.seq, target[1], needle_id_regex, 'f'))\n",
      "            needle_jobs.append((node, query_seq.seq, t, target_seq.seq.reverse_complement(), target[1], needle_id_regex, 'r'))\n",
      "    count += 1\n",
      "    if count < 1:\n",
      "        break \n",
      "    elif count % 500 == 0:\n",
      "        print \"submitted %d\" % count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview_local['run_needle'] = run_needle\n",
      "needle_jobs_async = lview_local.map_async(run_needle, needle_jobs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(needle_jobs_async)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "needle_jobs_async.ready()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickle.dump(needle_jobs_async.get(), open(\"/home/cfriedline/data7/assemblies/foxtail2/needle_jobs_async.pickle\",\"w\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "needle_jobs_async = pickle.load(open(\"/home/cfriedline/data7/assemblies/foxtail2/needle_jobs_async.pickle\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "needle_id_x = []\n",
      "needle_id_y = []\n",
      "needle_jobs_keep = []\n",
      "for i in np.arange(0, len(needle_jobs_async),step=2):\n",
      "    res_f = needle_jobs_async[i]\n",
      "    res_r = needle_jobs_async[i+1]\n",
      "    res = None\n",
      "    \n",
      "    if res_r and res_f:\n",
      "        if float(res_r[3]) > float(res_f[3]):\n",
      "            res = res_r\n",
      "        else:\n",
      "            res = res_f\n",
      "    \n",
      "    if res_f and not res_r:\n",
      "        res = res_f\n",
      "    \n",
      "    if res_r and not res_f:\n",
      "        res = res_r\n",
      "        \n",
      "    if res:\n",
      "        needle_id_x.append(res[2])\n",
      "        needle_id_y.append(float(res[3]))\n",
      "        needle_jobs_keep.append(res)\n",
      "    \n",
      "        if res[2] == 1 and float(res[3]) < 20:\n",
      "            print res_f[0:3]\n",
      "            print res_f[-1]\n",
      "            print \"***********************************\"\n",
      "            print res_r[0:3]\n",
      "            print res_r[-1]\n",
      "            \n",
      "            break\n",
      "        \n",
      "    if i % 10000 == 0:\n",
      "        print \"at %d\" % i\n",
      "print len(needle_id_x), len(needle_jobs_async)/2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#G-NODE_655968', u'B-NODE_101036\n",
      "q = blast_name_map['G-NODE_655968']\n",
      "t = blast_name_map['B-NODE_101036']\n",
      "blast_file = None\n",
      "for k, v in blast_index_dict.items():\n",
      "    idx = v['full']\n",
      "    if q in idx:\n",
      "        if t in idx[q]:\n",
      "            blast_file=k\n",
      "            break\n",
      "blast_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "blast_recs = NCBIXML.parse(open(blast_file))\n",
      "for rec in blast_recs:\n",
      "    if rec.query == q:\n",
      "        for alignment in rec.alignments:\n",
      "            for hsp in alignment.hsps:\n",
      "                print hsp\n",
      "        break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for j in needle_jobs_async:\n",
      "    res = j\n",
      "    if res:\n",
      "        if res[2] == 1 and float(res[3]) < 20:\n",
      "            print res[-1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots()\n",
      "fig.set_size_inches([10,10])\n",
      "ax.set_xlim([0,14])\n",
      "ax.set_ylim([0,105])\n",
      "plt.scatter(needle_id_x, needle_id_y, color=\"black\")\n",
      "plt.title(\"n=%d\" % len(needle_id_x))\n",
      "ax.set_xlabel(\"path length\")\n",
      "ax.set_xticks(range(14))\n",
      "ax.set_ylabel(\"percent identity\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "needle_id_dict = defaultdict(list)\n",
      "for x, y in zip(needle_id_x, needle_id_y):\n",
      "    needle_id_dict[x].append(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, ax = plt.subplots()\n",
      "fig.set_size_inches([10,10])\n",
      "ax.set_xlim([0,14])\n",
      "ax.set_ylim([0,105])\n",
      "for x in sorted(needle_id_dict.keys()):\n",
      "    y = np.mean(needle_id_dict[x])\n",
      "    plt.scatter(x, y,color=\"black\")\n",
      "    plt.errorbar(x, y, yerr=np.std(needle_id_dict[x]), color=\"red\")\n",
      "plt.title(\"n=%d\" % len(needle_id_x))\n",
      "ax.set_xlabel(\"path length\")\n",
      "ax.set_xticks(range(14))\n",
      "ax.set_ylabel(\"percent identity\")\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "needle_path_dict = {}\n",
      "for x in needle_jobs_keep:\n",
      "    if x:\n",
      "        if not x[0] in needle_path_dict:\n",
      "            inner = {x[1]:float(x[3])}\n",
      "            needle_path_dict[x[0]] = inner\n",
      "        else:\n",
      "            needle_path_dict[x[0]][x[1]] = float(x[3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in needle_path_dict.items():\n",
      "    print k, v\n",
      "    break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import copy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Remove nodes from filtered graph that globally align < 80%"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path_dict_filtered = copy.deepcopy(path_dict)\n",
      "sorted_keys = sorted(path_dict_filtered.keys())\n",
      "for node in sorted_keys:\n",
      "    data = path_dict_filtered[node]\n",
      "    for k, v in data.items():\n",
      "        to_remove = []\n",
      "        for target in v[0]:\n",
      "            if needle_path_dict[node][target] < 80:\n",
      "                to_remove.append(target)\n",
      "#         print k, to_remove\n",
      "        for r in to_remove:\n",
      "            v[0].remove(r)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_keys = sorted(path_dict_filtered.keys())\n",
      "dropped = 0 \n",
      "keep_nodes = set()\n",
      "for node in sorted_keys:\n",
      "    data = path_dict_filtered[node]\n",
      "    keep = True\n",
      "    for k, v in data.items():\n",
      "        if len(v[0]) == 0:\n",
      "            keep = False\n",
      "            break\n",
      "    if not keep:\n",
      "        dropped += 1\n",
      "    else:\n",
      "        keep_nodes.add(node)\n",
      "print \"%d dropped, %d kept\" % (dropped, len(keep_nodes))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_keys = sorted(path_dict_filtered.keys())\n",
      "for node in sorted_keys:\n",
      "    if not node in keep_nodes:\n",
      "        del path_dict_filtered[node]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(path_dict_filtered) ==  len(keep_nodes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Collapse all nodes into a single set for searching"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for k, v in path_dict_filtered.items():\n",
      "    v['all'] = set()\n",
      "    for i in [elem[0] for elem in [y for x, y in v.items() if not x == 'all']]:\n",
      "        for node in i:\n",
      "            v['all'].add(node)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Find reciprocal relationships"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contig_names = {}\n",
      "sorted_keys = sorted(list(path_dict_filtered.keys()))\n",
      "contig_ids = set()\n",
      "for i, k in enumerate(sorted_keys):\n",
      "    data = path_dict_filtered[k]['all']\n",
      "    assert len(data) >= 4\n",
      "    for x in data:\n",
      "        if not x in contig_names:\n",
      "            contig_names[x] = i\n",
      "            contig_ids.add(i)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(path_dict_filtered), len(contig_ids)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "contig_names_keys = contig_names.keys()\n",
      "with open(\"keep_after_global.txt\", \"w\") as out:\n",
      "    out.write(\"short\\tfull\\tsnp_id\\n\")\n",
      "    for k in contig_names_keys:\n",
      "        out.write(\"%s\\t%s\\t%d\\n\" % (k, blast_name_map[k], contig_names[k]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Compare snps between graph method and combining"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combine_pos = \"/home/cfriedline/eckertlab/foxtail/individuals_all/Green.raw.vcf.012.pos_filt.pos\"\n",
      "# graph_pos = \"/home/cfriedline/data7/assemblies/foxtail2/keep_after_global.txt\"\n",
      "graph_pos = \"/home/cfriedline/eckertlab/foxtail/individuals_all/keep_after_global.txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_set = set()\n",
      "for line in open(combine_pos):\n",
      "    combined_set.add(line.strip().split()[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "graph_set = set()\n",
      "for line in open(graph_pos):\n",
      "    line = line.strip()\n",
      "    if line.startswith(\"G\"):\n",
      "        graph_set.add(line.split()[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(combined_set & graph_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_set"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": ""
    }
   ],
   "metadata": {}
  }
 ]
}